from bs4 import BeautifulSoup, Comment
from config import BASE_URL, SEASON
from crawler.utils import get_soup


SCHOOL_URLS = [
    f"{BASE_URL}/cbb/schools/",
    f"{BASE_URL}/cbb/schools/?view=active"  # âœ… ç¨³å®šå¤‡ç”¨
]


def extract_schools_table(soup):
    """
    ä» soup æˆ–å…¶ HTML æ³¨é‡Šä¸­æå– schools è¡¨
    """
    table = soup.find("table", {"id": "schools"})
    if table:
        return table

    # ğŸ”¥ æ³¨é‡Šè§£å°
    comments = soup.find_all(string=lambda text: isinstance(text, Comment))
    for comment in comments:
        if 'id="schools"' in comment:
            comment_soup = BeautifulSoup(comment, "html.parser")
            table = comment_soup.find("table", {"id": "schools"})
            if table:
                return table
    return None


def fetch_teams():
    for url in SCHOOL_URLS:
        print(f"ğŸŒ å°è¯•æŠ“å–å­¦æ ¡åˆ—è¡¨: {url}")
        html = get_soup(url)
        if not html:
            continue

        soup = BeautifulSoup(html, "html.parser")
        table = extract_schools_table(soup)

        if not table:
            print("âš ï¸ å½“å‰å…¥å£æœªè¿”å› schools è¡¨ï¼Œå°è¯•ä¸‹ä¸€ä¸ªå…¥å£")
            continue

        teams = []
        for row in table.tbody.find_all("tr"):
            th = row.find("th")
            if not th or not th.find("a"):
                continue

            school = th.text.strip()
            link = th.find("a")["href"]

            teams.append({
                "school": school,
                "url": BASE_URL + link,
                "season_url": BASE_URL + link.replace(".html", f"/{SEASON}.html")
            })

        print(f"âœ… æˆåŠŸæŠ“å– {len(teams)} æ”¯ NCAA çƒé˜Ÿ")
        return teams

    print("âŒ æ‰€æœ‰ schools å…¥å£å‡å¤±è´¥ï¼Œå¯èƒ½è¢«ä¸´æ—¶é™æµ")
    return []